# ProjectBov2016_Wearable_Devices

### <왜 이 프로젝트를 진행했나요?>

BOV(Beyond Our Vision)는 목걸이 착용할 수 있는 웨어러블 디바이스와 안드로이드 앱으로 구성됩니다. 시각
장애인용을 위한 스마트한 기술을 제공하기 위해 시작한 프로젝트입니다. 시각장애인들의 눈이 되는 로봇을 개
발하고싶어 Beyond Our Vision. 즉 BOV라고 이름을 붙였습니다.

시각장애인의 편의를 위한 기존의 제품에는 점자생성기, 점자인식기, 문서를 읽어주는 기기, 저시력자를 위해 문
자를 확대해주는 문자확대기, 주행보조를 위한 스마트 흰지팡이, 시각장애인이 GUI 환경을 사용할 수 있도록 클
릭 시 음성으로 설명해주는 소프트웨어 등이 있습니다. 그러나 이 제품군들은 대부분 외국 제품에 의존하거나,
국내 기업이 생산하더라도 독점적인 판매구조를 가지고 있습니다. 또한 구매자인 시각장애인들이므로 구매 시장
의 수요가 매우 적어, 제품들이 가격이 매우 고가로 책정되어있는 현실입니다. 시각복지관을 방문하고 여러 시각
장애인들을 인터뷰하고 세 가지 요점을 정리하였습니다.

```
첫째, 시각장애인 보조 제품들 대부분이 고가로 측정 되어 있어 구매가 쉽지가 않다. 또한 성능이 만족스럽지가 않다.
TTS 소프트웨어의 경우 출시된 후 성능 업데이트가 이루어지지 않고, 다양한 플랫폼이나 신규 OS를 지원하지 않고, Windows XP만을 지원한다.

둘째, 시각장애인들은 규정된 흰지팡이 보행법에 따라 움직인다. 또 흰지팡이 사용에 매우 숙달되어 있어 도로가 잘 정리되어 있고,
보도블럭 표시가 잘 갖추어져 있다면 어려움 없이 보행할 수 있다.

셋째, 시각장애인 대부분 사용자 편의성을 제공하는 스마트폰 사용을 선호한다. 특히 TTS 기능과 음성 인식 비서 기능 이 잘 지원되는
애플의 iPhone이나 삼성의 Galaxy 제품군을 선호한다.
```

### <누가 이 프로젝트에 참여했습니까?>
```
프로젝트 명 : BOV(Beyond Our Vision)
개발인원 : 5 명

1. 배구환 / 부산대학교 전기공학과 / ghbaeproject@gmail.com
2. 방혜리 / 부산대학교 전자공학과 / 0421b@naver.com
3. 구태형 / 부산대학교 전기공학과 / koothe12@gmail.com
4. 정경엽 / 부산대학교 전기공학과 / ddubitobi@gmail.com
5. 김정욱 / 부산대학교 전자공학과 / kimmail93@naver.com

이 Github 계정의 프로젝트에 대한 문의사항은 참여멤버 또는 teamhmdproject@gmail.com로 보내주십시오.
```

### <그러면 이 프로젝트를 어떻게 진행했습니까?>

```
프로젝트 목표 : 시각장애인을 위한 보행 보조 웨어러블 디바이스 및 안드로이드 앱 개발
개발인원 : 5 명
개발기간 : 2016년 1월 ~ 2016년 9월
개발언어 : C++(워어러블 디바이스),  Java(안드로이드 앱)
개발툴 : Eclipse(웨어러블 디바이스, 안드로이드 앱), Android Studio(안드로이드 앱)
```
### <프로젝트 결과물을 실제로 볼 수 있습니까?>

```
(시연 동영상) 어플리케이션 시연 [Youtube link]
```
[![](http://img.youtube.com/vi/T2qjcdP_IJU/0.jpg)](http://www.youtube.com/watch?v=T2qjcdP_IJU "App1")

```
(시연 동영상) 카메라 작동 콘솔 화면 [Youtube link]
```
[![](http://img.youtube.com/vi/mcu8z8UR54o/0.jpg)](http://www.youtube.com/watch?v=mcu8z8UR54o "Cam1")

```
(시연 동영상) 점자블럭 인식 시연 [Youtube link]
```
[![](http://img.youtube.com/vi/yCbRhS-M3N8/0.jpg)](http://www.youtube.com/watch?v=yCbRhS-M3N8 "Cam2")

```
(소스 코드) https://github.com/teamhmd
```

### <프로젝트 진행 결과 및 수상 실적>

```
 2016 전국지능로봇 대학부 은상 수상
 2016 로봇 캡스톤 챌린지 특허청장상 수상
```

### <프로젝트 기획은 어떻게 시작했습니까?>

![image](https://user-images.githubusercontent.com/28957644/32310728-d63f3304-bfd7-11e7-83b7-cdfc6f834aeb.png)
![image](https://user-images.githubusercontent.com/28957644/32310724-d039f1e2-bfd7-11e7-9052-b5d846c89a1a.png)

[부산 시각장애인 복지관 방문 인터뷰]

저희는 시각장애인들의 보행 보조를 위한 기술 개발에 초점을 맞추었습니다. 개발 과정을 진행하기 전에 세 가지 목표를 정했습니다.
```
첫째, 휴대성이 간편 해야한다. 크기와 무게를 스마트폰의 크기를 넘기지 않는다.
또한 시각장애인이 흰 지팡이 사용을 방해하지 않도록 두 손이 자유로워야 한다.

둘째, 적은 예산으로 디바이스의 하드웨어를 구현 한다.

셋째, 스마트폰의 기능을 최대한 활용 하여 스마트한 기술을 개발한다.
```

저희는 시각장애인이 착용하는 웨어러블 디바이스와 이와 연동되는 앱을 구성하기로 개발 방향을 정했습니다.
웨어러블 디바이스는 착용자 전방의 보도블럭을 감지하고 이미지 평면의 픽셀 좌표를 실제 바닥의 좌표로 바꾸고 이 정보를 스마트폰으로 전송합니다. 안드로이드 앱은 웨어러블 디바이스에서 전송한 정보를 음성으로 출력하여 착용자에게 알려줍니다. 구글 TTS API를 이용하여 앱의 기능을 구현하였습니다. 또한 시각장애인이 랜드마크를 지정하고, 그 랜드마크에 접근하거나 이탈할 경우 음성으로 알려주는 앱의 기능을 구현하였습니다. 착용자 정보는 스마트폰의 GPS 정보를 사용하고 구글 맵 API를 이용하여 구현하였습니다.

### <웨어러블 디바이스 카메라는 어떻게 보도블럭의 정보를 획득합니까?>

웨어러블 디바이스의 카메라 모듈로부터 착용자 전방의 이미지를 촬영했습니다. 자이로미터로 카메라의 기울기를 측정하고 이미지 평면 상 착용자로부터 5 미터 이상의 영역을 분할하여 불필요한 컴퓨팅 연산을 방지했습니다. 카메라 모듈은 촬영 시 노출 설정과 노이즈 제거 필터를 적용할 수 있고, 검출할 컬러값의 경계를 설정하여 보도블럭의 노란색을 검출하였습니다. 검출한 보도블럭의 픽셀 좌표를 마이크로프로세서로 전송합니다.

### <픽셀상의 보도블럭 위치를 어떻게 실제 거리로 변환합니까? - 카메라 좌표계 변환>

검출한 보도블럭의 픽셀 좌표를 전달받아 경계값 이하의 작은 영역은 노이즈로, 경계값 이상의 큰 영역은 보도블럭이 아닌 것으로 판단했습니다. 또한 사용자에게 가장 가까운 보도블록을 선정하여 픽셀 좌표를 실제 바닥의 좌표로 변환하였습니다. 카메라 좌표계 변환은 핀홀 카메라 모델과 영상 기하를 참고하여 모델링하였습니다.

카메라의 각도 theta 와 카메라 중점(Principal point)부터 기준점(바닥)까지의 거리 d를 알면 실제 바닥 상에 보도블럭이 위치한 좌표 (v,
 l+u)를 계산할 수 있습니다. 카메라의 각도 theta는 자이로미터로 측정하였고, 카메라의 중점부터 기준점까지의 거리 d는 적외선 거리 센서를 통해 측정하였습니다. 계산된 좌표는 거리 r_diff과 각도 phi로 환산한 극좌표 형태 (r_diff, phi)로 바꾸어 안드로이드 앱으로 전송하였습니다.

![image](https://user-images.githubusercontent.com/28957644/32310730-dd722ed8-bfd7-11e7-90a3-6bd70b150d8f.png)


웨어러블 디바이스의 소스 코드는 [다음 페이지](https://github.com/teamHMD/ProjectBov2016_Wearable_Devices)에서 볼 수 있습니다.
```
https://github.com/teamHMD/ProjectBov2016_Wearable_Devices
```

### <안드로이드 어플리케이션은 어떤 기능을 수행합니까?>

구글 TTS API를 사용하여 전달받은 보도블럭의 위치를 착용자에게 음성으로 전달하였습니다. 사용자가 랜드마크를 설정하면, 구글 맵 API를 사용하여 랜드마크의 GPS 좌표를 저장하였습니다. 또한 사용자가 해당 랜드마크의 위치를 알고 싶은 경우 사용자 현재 GPS 좌표와 저장된 랜드마크의 거리를 환산하여 음성으로 전달하였습니다. 사용자가 랜드마크와 30m 이내로 접근할 경우 해당 랜드마크에 접근중임을 음성으로 알렸고,
해당 랜드마크에서 이탈할 경우 이탈함을 음성으로 전달했습니다.

### <안드로이드 어플리케이션의 UI는 어떻게 구성되어 있습니까? 사용자인 시각장애인에게 어떻게 정보를 전달합니까?>

시각장애인이 음성으로 명령을 전달할 수 있도록 VTT(Voice To Text)를 적용했습니다. 랜드마크를 음성으로 검색할 수 있도록 구현했습니다. 시각장애인분들이 스마트폰의 화면을 볼 수 없어도 인터페이스의 위치를 기억하고 능숙하게 스마트폰 앱을 사용하는 것에 착안하여, 직관적인 GUI와 레이아웃 배치를 적용했습니다.


BOV 안드로이드 어플리케이션의 소스 코드는 [다음 페이지](https://github.com/teamHMD/ProjectBov2016)에서 볼 수 있습니다.
```
https://github.com/teamHMD/ProjectBov2016
```

### <웨어러블 디바이스 하드웨어는 어떻게 구성됩니까?>

![image](https://user-images.githubusercontent.com/28957644/32310734-e1411ab0-bfd7-11e7-9bfb-29f7cf7518df.png)

웨어러블 디바이스의 하드웨어는 마이크로프로세서, 카메라 모듈, IR(적외선 거리 센서), 자이로미터, 블루투스 통신 모듈, 파워 서킷, 배터리로 구성하였습니다. 배터리는 재충전이 가능한 LiPo를 사용하였고, 충전 테이블은 MicroUSB 단자를 사용하여 범용성을 높였습니다. 또한 파워 서킷은 스마트폰 충전기 입력전압인 5V/3A을 기준으로 구성하여 별다른 충전기가 필요하지 않도록 제작했습니다.

### <웨어러블 디바이스의 외부 프레임과 바디 제작는 어떻게 만들었습니까?>

![image](https://user-images.githubusercontent.com/28957644/32310736-e493148e-bfd7-11e7-81d0-cadb7ca4fedb.png)
![image](https://user-images.githubusercontent.com/28957644/32310737-e6b055b0-bfd7-11e7-8351-8865a02da6b6.png)

웨어러블 디바이스의 외부 프레임과 바디는 3D 프린팅으로 제작하였습니다. 설계는 123D Design 툴을 사용하였고, 학교 내의 3D 프린터를 사용하여 제작하였습니다. 아래 사진은 웨어러블 디바이스의 프로토타입 설계도입니다. 프로토타입에는 웨어러블 디바이스에 독립적인 스피커가 있었는데, 시각장애인 분들의 피드백을 통해 음성출력부분을 안드로이드 앱 부분으로 이동시켰습니다. 스피커와 주변회로를 제거하고, 거리 측정 센서를 재배치하여 최종 모델의 크기를 크게 줄였습니다.



### <프로토타입 모델의 실물>

![image](https://user-images.githubusercontent.com/28957644/32310741-ec417c8e-bfd7-11e7-9333-c0a6322899fb.png)

### <최종 모델의 실물>

![image](https://user-images.githubusercontent.com/28957644/32310746-f1d846be-bfd7-11e7-9075-89dc5971abc1.png)

![image](https://user-images.githubusercontent.com/28957644/32310749-f5bc19f4-bfd7-11e7-9b63-55644f1fadca.png)

### <프로젝트를 진행하고 아쉬운 점이 있습니까? – 웨어러블 디바이스>

컬러 기반의 보도블럭 검출을 구현하는 초보적인 수준의 영상처리를 통해 주요 기능을 구현한 점입니다. 컬러 검출은 외부 환경(조도의 변화, 유사한 컬러를 가진 장애물)의 영향에 능동적으로 대처하기 어렵다는 약점을 가지고 있습니다. 보도블럭의 엣지 검출과 패턴 인식을 통해 보도블럭을 검출한다면 여러 형태(다른 색상, 다른 패턴)의 보도블럭을 안정적으로 검출할 수 있을 것입니다. 또한 카메라 렌즈를 통해 촬영된 이미지 왜곡으로 카메라 좌표 환산 측정값을 제거하지 못했습니다. 이는 영상처리와 컴퓨터 비전에 대해 공부해 보는 계기가 되었습니다. 이후 캘리브레이션을 통해 왜곡된 이미지를 보정해야함을 알게 되었습니다.

### <프로젝트를 진행하고 아쉬운 점이 있습니까? – 안드로이드 어플리케이션>

구글 맵 API를 사용하여 착용자의 위치와 랜드마크와의 거리를 감지하는 방법을 폴링(Polling)을 통해 검출했습니다. 시스템에 대한 공부를 더 해본 결과 안드로이드의 서비스에서 인터럽트를 통해 랜드마크와 가까워지면 이벤트를 발생시켜 대응하는 방식으로 구현하는 것이 앱 자원 관리 측면에서 효과적임을 알게 되었습니다. 또한, 프로젝트 당시 디바이스와 앱 구현을 위한 프로그래밍 경험이 부족했기에 소스 코드가 가독성이 좋지 않고 효율적인 구현을 실현하지 못했습니다. 이는 프로그래밍과 관련 컴퓨터 공학 개념을 공부하는 계기가 되었고 지금은 부족한 점을 보완하고 더 다양한 경험을 쌓기 위해 여러 프로젝트를 경험해보고 있습니다.
